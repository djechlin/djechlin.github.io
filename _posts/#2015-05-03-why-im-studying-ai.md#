---
title: Why I'm studying AI
layout: post-index
---

When I have been ask why I want to study AI formally, I have replied with muddled allusions to its mathematical beauty, the impending dawn of superintelligence, and how terrifying it is that so many jobs are being automated. The thing to remember is that AI is semiotically huge. It encompasses a desire to understand why we are intelligent, the keys to what are souls are, insight into the spiritual pursuit of consciousness usually left to yogic methods, the pursuit of great scientific discoveries that might save the planet in its fully ambitious sense, the economic terror of what happens when there is very little left for humans to do, the adventure in underpinning the social sciences with elegant computational models, and the conditions under which the great dystopian novels that prognosticate the triumph of tyranny over hope (because what hope is left when minds and social systems are mastered by those in control?).

Somehow, when I want to express my conviction that studying AI is a good and right thing to do, I begin wanting to express my attraction to the beauty of understanding consciousness, but all I end up talking about are the most paranoid of my anxieties and fears. This is partly because my desire to study AI is legitimately complex. I have the feeling that I am at a point in my life when I can pursue *real* goals - whatever that means - and therefore load my desires to be erudite, scientific, accomplished, and worldly, into one simplified pursuit. My idea of what AI is spans from the spiritual to the terrifying, and I have acted as though studying AI is a final act of confronting of my deepest anxieties, where I must expose them for what they are. I suppose this idea is right, but for the wrong reasons. Writing a piece like this is far more therapeutic than the actual study will be.

So in this piece I want to unwind what a few of my purest reasons for studying AI are. Some of these reasons are good and some are misguided, but I want to treat them all as legitimate voices to be engaged with individually.

### 1. Not long ago, I found the study of AI to be mathematically beautiful and spiritually relevant

Around 2012, this voice was very strong and very captivating. I was very, very happy when I was reading *Godel, Escher, Bach* and the author's spiritual sequel (put not intended), *I Am A Strange Loop*. The way I would describe these books: take the harried descriptions I gave of AI above, and imagine an author who starts with an almost literary conviction that human existence is good and beautiful, and journeys the reader through the most delightful yet strangely rigorous presentation of the isomorphism between mathematics and thought. In other words, the optimism in them is as real as the theory itself, but it is imbued by the author. It's no wonder I don't find this optimism in more modern pieces I've read on AI since the books were published.

I was also very bipolar and somewhat manic when reading these books. When I was untreated, I was in the funny situation that the only salve for my anxieties was my manic states. (This may be a good time to say my anxieties have more recently been diagnosed as OCD. So they are coherent and vulnerable to therapy in their own right.) Now the manic states are gone and I have found it hard to rekindle this optimism, although I do want to. I'm undecided whether it's a fool's errand. I believe my therapy with bipolar disorder has more room for the light of day, but chasing the traces of certain manic states should not be on my perennial to-do list.

### 2. My philosophical interest has turned dark, but I want to confront it anyway and become more worldly

I don't really know how to confront my deeper anxieties about inequality and suffering, and my fear of how AI - whether unintelligent and merely job-eliminating or superintelligent and tyrannizing - has become a symbol of this. My earlier, optimistic but still heavy interest in the field has given way to this, unfortunately, without my stopping to think of whether this is what I really want or whether earlier reasons apply. I think it's okay to study the field in spite of this. I really don't like that my greatest sources of knowledge of AI and its implications are coming from crappy news and an anxious mind. Maybe I should turn off the blog-reading and occasional sensationalized remark of Elon Musk or whoever and read *The Economist*. I'm not sure if studying AI as a masters degree student is going to have much to do with this. Perhaps not, but perhaps becoming informed qua a scientist is a right place to start.

### 3. I have a long-running conviction that one's career should derive from *a priori* interests, and the time is now

I remember when I was debating between a Ph.D. in mathematics and a Ph.D. in history of science, consequences be damned. I became more practical but that voice has not totally vanished. All it really takes is an opportunity to forge my career out of a deep scientific interst for me to change gears, and, lo and behold, I work at a great company that applies AI scientifically and at scale, and extraordinarily supports the pursuit of higher education of its employees.

As an aside, I should remember that a computer science education is bigger than just AI. Completing the masters degree will be really good for me anyway. I can turn AI into a leaf in this study if I need to.  g